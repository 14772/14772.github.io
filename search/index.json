[{"categories":["学习"],"contents":"军理复习 前半部分 1、 人民军队政治工作的三大原则是：\n1  军民一致，官兵一致，瓦解敌军   2、 习近平在党的十九大报告中指出，必须全面贯彻新时代党的强军思想，贯彻新形势下军事战略方针，建设强大的现代化\n1  陆军、海军、空军、火箭军和战略支援部队   3、 邓小平揭示了\n1  和平与发展   是当代世界的主题，在和平与发展的关系中，\n1  发展   是核心问题。\n4、 国家的地缘环境是指影响国家安全的\n1  地理位置、地理特征   以及与地理密切相关的国家关系等因素。\n5、 信息化战争，是以\n1  信息技术   支配整个高技术武器装备体系，以\n1  信息攻防   为主要作战方式，在核威慑条件下，全方位进行的立体战争。\n6、 党在十九大提出：在新时代的强军目标内涵包括四个坚持：坚持\n1  政治建军、改革强军、科技兴军、依法治军   7、 根据有关法律法规，公民应承担的国防义务：一是\n1  应征服兵役   二是参加民兵组织；三是参加军事训练；四是\n1  接受国防教育   五是预备役军官要依法履行登记手续；六是公民应当支持国防建设。\n8、 党的十三大报告把邓小平同志的战略思想概括为\n1  和平 和 发展   是当代世界的主题。\n9、 当前的国际战略格局呈现出\n1  一超多强   的态势。\n10、 《孙子兵法》的“全胜”思想是指：\n1  不战而屈人之兵   11、 中国共产党第十九次全国代表大会报告指出，坚持走\n1  中国特色强军之路   全面推进\n1  国防和军队现代化建设   12、 国防的目的是\n1  捍卫国家的主权、维护国家统一和领土完整 、维护国家安全   13、 习近平新时代中国特色社会主义思想明确了党在新时代的强军目标是建设一支\n1  听党指挥、能打胜仗、作风优良   的人民军队，把人民军队建设成为世界一流军队。这也是实现“两个一百年”奋斗目标、实现中华民族伟大复兴的战略支撑。\n14、 《孙子兵法》的作者是\n1  孙武   15、 1935年1月的\n1  遵义会议   确立毛泽东在党内和红军中的领导地位。\n16、 1  和平和发展   仍然是当今世界的两大主题。\n17、 C4ISR系统是指：指挥、控制、通信、计算机、\n1  情报、侦察   、监视系统的简称。\n18、 中国人民解放军诞生于\n1  1927年8月1日   19、 军事高技术包括两类，即\n1  军事基础高技术和军事应用高技术   20、 我国“两弹一星”是指：\n1  原子弹、氢弹、人造地球卫星   （或核弹、导弹、人造卫星）。\n21、 军事思想是关于\n1  战争和军事   问题的高层次的系统的理性认识。\n22、 中国人民解放军的主要任务是：\n1  巩固国防，抵抗侵略，保卫祖国，保卫人民的和平劳动，参加国家建设   23、 信息战争争夺的核心是\n1  制信息权   24、 战争起源于\n1  生产资料私有制   25、 人民战争的本质是\n1  为人民利益而进行的战争   26、 人民军队的性质是\n1  在中国共产党的绝对领导下，执行无产阶级革命政治任务的武装集团   27、 党的十九大指出要适应世界新军事革命发展趋势和国家安全需求，提高建设质量和效益，确保到\n1  2020年   基本实现机械化，信息化建设取得重大进展，战略能力有大的提升。\n28、 党的十九大指出：力争到\n1  2035年   基本实现国防和军队现代化。\n29、 党的十九大指出军队建设要与国家现代化进程相一致，到\n1  本世纪中叶   把人民军队全面建成世界一流军队。\n30、 2001年8月31日，我国第九届全国人民代表大会常务委员会第二十三次会议通过，确定全民国防教育日是\n1  9月第三个星期六   31、 国防历史给予我们的启示是\n1  政治昌明是国防巩固的根本   32、 中国政府解决台湾问题的基本方针是\n1  “和平统一、一国两制”   33、 我国最高国家军事机关是\n1  中央军事委员会   34、 我国陆地国土面积是\n1  960万平方公里   35、 国防的主体是国防活动的实行者，通常为\n1  国家   36、 孙子兵法《火攻》篇提出了\n1  慎战   的思想。\n37、 精确制导武器是指采用精确制导技术，直接命中概率在\n1  50%以上   的武器。\n后半部分 38、 适合于攻击固定目标的制导方式是指\n1  自主式制导   39、 中国人民解放军海军成立于\n1  1949年4月23日   40、 中国领土最南端是\n1  曾母暗沙   41、 中国的陆地国土最东段是\n1  黑瞎子岛   42、 “兵者，国之大事”这句话岀自《孙子兵法》的\n1  《计篇》   43、 1  《孙子兵法》   是现存最早、影响最大的兵书，编写于我国春秋末期。\n44、 在1991年海湾战争中美军首次使用了\n1  “战斧式”   巡航导弹。\n45、 国家政治利益的核心是\n1  国家主权   46、 国防行为的主体是\n1  国家   47、 我国海上边界线长\n1  1.8万公里   48、 国防的目的是\n1  保护国家主权统一、领土完整和安全   49、 1  侦察   是军队为了获取敌情和有关作战的其他情况而采取的行动。\n50、 国防按性质和建设目标可以分为\n1  扩张型国防，中立型国防，联盟型国防和自卫型国防。   51、 1  保卫国家安全，维护国家权益，反对霸权主义，维护世界和平   是国防的根本目的。\n52、 习近平在党的十九大报告中指出，必须全面贯彻新时代党的强军思想，贯彻新形势下军事战略方针，建设强大的现代化\n1  陆军、海军、空军、火箭军、战略支援部队   53、 一个国家的主权包括\n1  对内的统治权、对外的独立权   54、 国防的对象，是指国防所要防备和抵御的行为。根据《中华人民共和国国防法》的界定，国防的对象是指\n1  侵略和武装颠覆   55、 公民的国防义务包括\n1  服兵役、接受国防教育、保护国防设施、保守国防秘密、支持国防建设、协助军事活动   56、 我国武装力量主要包括\n1  中国人民解放军现役部队和预备役部队、中国人民武装警察部队和民兵组织   57、 为适应信息化战争要求，将来的军队的发展方向是\n1  小型化、 一体化、 智能化   58、 军事高技术对军队建设的影响\n1  军队结构不断优化、作战指挥系统“扁平网络化”、军队人员结构和素质大幅提升   59、 侦察与监视技术根据运载侦察与监视技术设备的平台的活动空域，可分为\n1  航天侦察与监视设备、 航空侦察与监视设备、地面侦察与监视设备、水中侦察与监视设备   60、 目前我国海军共有三大舰队\n1  北海舰队、东海舰队、南海舰队   61、 信息化武器装备大体可分为\n1  软杀伤和硬摧毁   两大类。\n62、 当前我国共有\n1  14   个陆上邻国，其中与我国仍存在边界领土纠纷的是\n1  印度和不丹   63、 《武经七书》由我国古代七部兵书汇编而成，其中有\n1  5   部成书于春秋战国时期。\n64、 信息化战争的主要特点\n1  战争目的的有限化，信息战争争夺的核心是制信息权，作战空间多维化，作战行动实时化，作战行动精确化，持续时间短促化   65、 毛泽东军事思想科学体系包括：\n1  战争观和军事方法论，人民军队思想，人民战争思想，人民战争的战略战术思想，国防建设思想   66、 我国维护周边环境安全的总方针是固北、稳西、安东、拓南。对美：促合作、不示强；对日：促稳定、不示弱；对俄：低调、务实、谈合作；对奥：趋利避害、不计较；对印：求共赢共荣；对欧：以经促政；对朝：积极引导，防止失控；海洋方面：东海争锋相对、南海稳中求进。\n67、 军事高技术的主要特点：高智力、高速度、高竞争、高保密、高效益、高风险、高投资。\n68、 国家安全是指国家政权、主权、统一和领土完整、人民福祉、经济社会可持续发展和不受内外威胁的状态，以及保障持续安全状态的能力。\n当代国家安全主要包括10个方面的基本内容，即国民安全、领土安全、主权安全、政治安全、军事安全、经济安全、文化安全、科技安全、生态安全、信息安全。\n69、 信息化战争的发展趋势是信息化作战平台将成为战场支撑；智能化武器装备将大量涌现；军队将向小型化、一体化和智能化方向发展；作战思想将出现重大调整；主要作战样式将出现重大改变。\n70、 对习近平强军目标的基本认识\n（一）习近平站在实现中华民族伟大复兴中国梦的时代高度，鲜明提出建设一支听党指挥、能打胜仗、作风优良的人民军队这一党在新形势下的强军目标。是新的历史条件下我们党建军治军的总方略。\n坚决听党指挥，要能打仗、打胜仗，要保持光荣传统和优良作风。强军目标强调的这三条，决定着军队发展方向，也决定着军队生死存亡。\n（二）听党指挥是灵魂，决定军队建设的政治方向。新形势下，必须铸牢听党指挥这个强军之魂，认真贯彻落实军委主席负责制，任何时候任何情况下都坚决做到保持一致、维护权威、听从指挥，确保部队绝对忠诚、绝对纯洁、绝对可靠。\n（三）能打胜仗是核心，反映军队的根本职能和军队建设的根本指向。军队首先是一个战斗队，必须坚持一切建设和工作向能打胜仗聚焦。新形势下，必须扭住能打仗、打胜仗这个强军之要，牢固树立战斗力这个唯一的根本的标准，更加坚定自觉地抓备战谋打赢，发扬我军大无畏的英雄气概和英勇顽强的战斗作风，提高我军信息化条件下威慑和实战能力，做到召之即来、来之能战、战之必胜。\n（四）作风优良是保证。新形势下，必须穷实依法治军、从严治军这个强军之基，把作风建设作为军队一项基础性长期性工作抓紧抓实，坚持全心全意为人民服务的根本宗旨，发扬艰苦奋斗精神，锻造铁的纪律，纯正部队风气，确保我军血脉永续、根基永固、优势永存。\n71、 中国国防历史给我们的启示：只有经济强盛才能有强大的国防；只有政治昌明才能有巩固的国防；只有民族团结和统一才能有坚强的国防；\n72、 信息化武器装备对现代战争的影响可概括为侦察立体化、指挥控制智能化、目标打击精确化、防护综合化、反应快速化五个方面。\n73、 现阶段，美国对中国的策略主要有：\n1  政治高压、经济掏空、军事遏制、地缘包围、内外夹击、持续干扰、贸易围堵   74、 三大纪律是：\n1  一切行动听指挥；不拿群众一针一线；一切缴获要归公。   八项注意是：\n1  说话和气；买卖公平；借东西要还；损坏东西要赔；不打人骂人；不损坏庄稼；不调戏妇女；不虐待俘虏   75、 影响现代战争胜负因素包括很多方面。\n广义上来说，影响战争胜负的因素主要包括政治、经济、军事、外交、文化等多个方面。其中经济实力是基础，国防力量是核心，外交环境是保障，文化和民族凝聚力是精神支柱。具体可结合材料展开阐述。\n但是我们也应该注意到，随着信息技术、人工智能、5G通信、云计算技术的发展和应用，信息化战争形态基本形成，智能化战争时代也悄然到来。相比于过去的战争形态，战争的制权争夺演变更新、制胜机理颠覆传统、作战形态发生质变、战斗力生成机制不断变革。例如，作战形态发生质变。无人化是机械化信息化智能化融合发展的集中体现，无人化体系作战在智能化时代将成为常态。同时，基于AI的无人化技术，将逐步拓展到网络攻防、电子对抗、多源感知、关联印证、人物跟踪、舆情管控等其他领域。具体可结合无人作战装备的特点、应用案例进一步分析阐述。\n","permalink":"https://sukun.xyz/%E5%86%9B%E7%90%86%E5%A4%8D%E4%B9%A0/","tags":["学习"],"title":"军理复习"},{"categories":null,"contents":"主题作者 本网站采用 Hugo-LoveIt 主题，下方是主题作者的 GitHub 链接。\n\rDillon\r\"LoveIt主题作者\"\r\r\r\r大佬们 JAVA \r雨临Lewis的博客\r\"不想当写手的码农不是好咸鱼_(xз」∠)_\"\r\r\r\r本站友链信息 1 2 3 4  name=\u0026#34;Sukun的博客\u0026#34; url=\u0026#34;https://sukun.xyz\u0026#34; logo=\u0026#34;https://sukun.xyz/images/德丽莎观星.png\u0026#34; word=\u0026#34;Sukun的博客，记录学习历程！\u0026#34;   交换友链 注意  各位大佬想交换友链的话可以在下方留言，我看到后将以回复+邮件的形式通知！   你需要留下以下信息：\n1 2 3 4 5 6 7 8 9 10  //必填 name=\u0026#34;站点名称\u0026#34; //必填 url=\u0026#34;站点地址\u0026#34; //必填 logo=\u0026#34;你的站点图标或个人头像\u0026#34; //必填 word=\u0026#34;站点描述\u0026#34; //选填——默认分组是大佬们 group=\u0026#34;分组\u0026#34;   警告  如果贵站存在以下情况之一：\n链接失效、无法访问、删除本站友链、友链入口不易找到。\n我将删除贵站友链并邮件通知，直至贵站恢复正常为止！\n   ","permalink":"https://sukun.xyz/friends/","tags":null,"title":"友链墙"},{"categories":["C语言"],"contents":"C语言系列（一） 前言  本系列文章旨在记录学习过程中遇到的C语言难题以及充当错题集的作用。   ","permalink":"https://sukun.xyz/c%E8%AF%AD%E8%A8%80%E7%B3%BB%E5%88%97%E4%B8%80/","tags":["C语言"],"title":"C语言系列(一)"},{"categories":null,"contents":"   new Artitalk({ appId: 'LLhNra6D2fqcyOGJYWIrwoB8-MdYXbMMI', // Your LeanCloud appId appKey: '1m4bN4Gx2xYFmRwyrT1Y1qPa' // Your LeanCloud appKey })  ","permalink":"https://sukun.xyz/bbs/%E5%85%AC%E5%91%8A%E7%95%99%E8%A8%80/","tags":null,"title":"公告留言"},{"categories":["生活"],"contents":"站点日志 站点日志  不断更新中    2021年 2021年10月 大一参加学校工作室招新，购买了云服务器，顺便利用 WordPress 开通了我的第一个私人博客。（顺便提一嘴，服务器至今仍在跑青龙面板为我捞点豆子）\n2021年11月 嫌弃 WordPress 过于臃肿，且对技术锻炼程度不高，遂放弃 WordPress 转投 Hexo\n2022年 2022年1月 2022年1月1日 元旦第一天，突然想起那个开通了之后一直没写的博客，又发现 Hugo 在博客上是更好的选择，于是本网站就此诞生！\n2022年1月2日 开始写文章了！\n2022年1月3日 为网站添加了小游戏 mikutap。\n2022年1月4日 加入了抓猫小游戏，一起来抓猫呀！\n2022年1月5日 添加了更丰富的评论功能，采用 Waline 实现。\n添加了站点日志、友链墙。\n添加了 artitalk 实现的 BBS 功能——公告板/留言板！\n2022年1月6日 添加了站点持续时间功能。\n2022年1月7日 添加了搜索、GitHub conrner 、最近更新文章、上次更新时间功能\n把源码和网页文件分开为了两个仓库。\n","permalink":"https://sukun.xyz/logs/","tags":["站点日志","生活"],"title":"站点日志"},{"categories":null,"contents":"一起来抓猫 点击圆点围住猫咪，别让它到达地图边缘！\n    window.game = new CatchTheCatGame({ w: 11, h: 11, r: 20, backgroundColor: 0xeeeeee, parent: 'catch-the-cat', statusBarAlign: 'center', credit: '一起来抓猫！' });  ","permalink":"https://sukun.xyz/games/catch-the-cat/","tags":null,"title":"Catch the Cat"},{"categories":["web"],"contents":"Hugo博客系列（一） 前言 为什么要有自己的博客？ 写博文能很好地分享自己的想法，能记录生活，还能充当一个电子笔记的作用，有效防止今后某一天面对一个以前遇到过的问题但现在不会解决的情况出现。一篇好的博文能为你带来大量的流量，你可以在搜索引擎中搜索到自己，我相信这是一件足够令人雀跃的事情。并且你还能利用他做一篇网页简历，当你找工作时你可以有着更加花里胡哨的简历！除此以外，你还能通过交换友链建立一个优质的社交圈，因为大家都写了很多高质量的文章，你能与他们进行深入交流，这不像同学圈一样脆弱，它能稳定存在很久！\n在其他博客平台写作你讲或多或少地受到限制，想自己 DIY 页面还得向官方申请，甚至不会审批通过。而且你无法使用多种多样的第三方插件，还得面对审查，写的文章有可能被删除、撤回。有广告干扰，任谁也不喜欢看着一篇文章然后突然蹦出来一个广告吧？当然，你也可以自己接点广告在网站上。\n常见博客框架的选择 hexo hexo 以前影响力还不错，但这几年已经不如从前人们预判的那么发展的好了，GitHub 上 hexo 项目有着 34k 个 star 看出，其中最为出名的主题便是 Next，有着 15.7k 个 star，这也是因为 Next 目前是 hexo 主题中功能最齐全最好用的一个。而如此之多的人使用也就意味着 hexo 这个框架的作者用收到非常多的反馈，因此 hexo 更新优化做的很好，作者也很有动力继续做下去。\n但是这样的一个框架缺点也是有的：\n  环境配置麻烦\n因为要使用 hexo 你得在本地安装 Node.js、Git，会熟练使用 GitHub，而且由于 GitHub 的特殊性，你还得学会翻墙，不然还用不了，这就对一点基础都没有的小白不是很友好了。\n  无后端\n这意味着你没有一个后台还方便地对网站进行操作，只能通过先写好 Markdown 文件然后 Git 推送到云端。并且原生的 hexo 是没有评论系统的，想加评论还得找第三方评论系统。除此以外，一旦本地文件被你不小心删除掉了，那当你下次 push 的时候你之前的博文也就跟着丢失了。\n  渲染时间久\n200 篇左右的博文用 Hexo 需要 10 分钟去生成静态网页，当你写博客写的时间久了之后文章多了起来，相信我，你会无法忍受这种折磨。\n  总结：hexo 适合有一定基础的人，然后写博客时间不长或者只是随便写来玩的人。当然尤其其广泛的传播性，当你遇到问题的时候拿到网上去搜一般都是有解决方案的，这也可以为你省下一点力气。\n最后，如果你想用 hexo，我建议主题用 Next。\nHugo Hugo 几年前的影响力是不如 hexo 的，但现在越来越多的人从 hexo 迁移到了 Hugo，Hugo使用人数也多了起来，GitHub 上 Hugo 项目有 56.2k 个 star，已远远超过了 hexo，因此你也不用太担心 Hugo 会不会太小众化的问题，但是 Hugo 上的主题选择会更少一些，其中最受欢迎的是 wowchemy，但也仅有 6.1k 个star，而本站采用的是 LoveIt 主题，它的 star 就更少了，才 1.6k 个。当然，如果你是搞前端开发的，或者乐意自己写主题，那这些就不重要了。\nHugo优点：\n  速度快\nHugo 采用 Go 语言编写，它的速度用作者的话来形容就是世界上最快的构建网站工具。并且 Hugo 是即时渲染的，这意味着你可以边写边改样式，直到你满意为止。即使是你写了几百篇文章，它也能在几秒之内全部渲染完成。\n The world’s fastest framework for building websites\n   配置更为简单\n你需要安装只是 Hugo，不像 hexo 还得安装 Node.js。并且Hugo 中是不区分站点和主题的配置文件的，Hugo 中只有一个位于站点根目录下的 config.toml 配置文件，你只用在这里面进行修改就可以了。\n  方便自定义\n你可以在不修改主题文件的前提下方便地定制主题。在 Hugo 中，如果你想要定制主题，你只需在站点目录下新建相应的文件即可。这是非常利于主题的维护的，你只需使用 Git 的 submodule 的方式安装 Hugo 的主题，然后更新时只需直接在站点根目录下敲一条命令回车即可，非常方便！\n  缺点：\n主题比较少，很可能大家都是用的同一个主题，并且主题作者更新会更少一点。\n总结：如果你喜欢 DIY，我建议使用 Hugo。如果你是个专业博主，写了很多文章需要渲染，我建议使用 Hugo！\nTypecho 这是一个非常轻量级的博客框架，但是需要你拥有一个服务器。并且它对服务器要求极低，即使只有 512M 内存或是更低，它也能跑起来。它可以满足你对博客的基本需求，而且 Typecho 是带后端的，意味着只要你能上网，你就可以自由地写你的文章，不会被设备所拘束。当然，你将免除配置环境的苦恼。\n缺点：\n  更新慢\n奇慢无比，作者已经 9 年没有进行更新了，一些插件也已经不能用了。\n  自由度低\n你不能随心所欲地进行 DIY，当然，如果你只是用来写博客的话问题不是很大。\n  WordPress 世界上最受欢迎的建站工具！具体有多受欢迎？每三个网站就有一个是 WordPress 搭建，并且美国白宫自2017年起，其官网 Whitehouse.gov 网站的內容管理系統（Content management system，CMS）从 Drupal 换成 WordPress！\n WordPress 是一个以 PHP 和 MySQL 为平台的自由开源的博客软件和内容管理系统。WordPress 具有插件架构和模板系统。截至2018年4月，排名前1000万的网站中超过30.6%使用WordPress 。WordPress是最受欢迎的网站内容管理系统。全球有大约30%的网站(7亿5000个)都是使用WordPress架设网站的。WordPress 是目前因特网上最流行的博客系统。\n 并且 WordPress 并不只是可以用来写博客，它能用来打造一切你想要的网站，哪怕是用来建个电商网站也没有问题！\n优点：\n  超广泛传播性\n你在使用 WordPress 遇到的任何问题，你都可以在网上找到对应的解决方案，它的使用人数之多以至于每一个坑都有人替你趟过了！\n  DIY 自由度高，难度低\n你可以随心所欲地添加插件，WordPress 提供了大量的优质插件，甚至有大量的人就以制作 WordPress 上的插件谋生！\n  安装简单\n网上有非常多的 WordPress 一键安装脚本，你可以根据自己的需求进行选择，无需面对安装过程中的问题！并且其安装时间非常短，只需要5分钟就能搞定！\n  缺点：\n  需要有一定性能的服务器\nPHP，MySQL这些对服务器有一定的要求，会占用比较多的内存，它不像 Typecho 一样轻便。\n  太过臃肿，不简洁\n太多的功能与选择造成了页面的繁琐，并且你会对着页面一直修改，这不利于你专心地撰写博文。\n  总结：适合有服务器，懒得折腾环境配置，喜欢开箱即用的人。\nHugo快速上手教程 Hugo安装 首先，请前往 GitHub 上下载最新版的 Hugo 压缩包，Releases · gohugoio/hugo (github.com)，建议选择 extended 版本，这将更有利于后续的 DIY 操作！\n下载完成后解压到一个你认为合适的位置，然后把 hugo.exe 所在的文件夹添加至环境变量中的 Path 中即可。\n当然，你也可以采用源码编译的方式进行安装，这里就采用最简单的方法了。\n注意  如果你的 Path 变量字符数达到上限了，你可以新建一个变量，然后在这个变量下添加你要添加的 Path，然后再在 Path 中添加一个变量值为 %name% 即可。\n   检查一下上一步操作是否正确\n1  hugo version   然后找一个合适的文件夹，在该目录下输入以下指令新建一个 Hugo 项目\n1 2  hugo new site my_website cd my_website   Hugo主题选择、安装与快速上手 我这里采用 LoveIt 主题进行演示，事实上还有很多主题也很棒，比如 even、meme、wowchemy。\nLoveIt 主题的仓库是: https://github.com/dillonzq/LoveIt.\n你可以下载主题的 最新版本 .zip 文件 并且解压放到 themes目录.\n另外, 也可以直接把这个主题克隆到 themes 目录:\n1  git clone https://github.com/dillonzq/LoveIt.git themes/LoveIt   或者, 初始化你的项目目录为 git 仓库, 并且把主题仓库作为你的网站目录的子模块:\n1 2  git init git submodule add https://github.com/dillonzq/LoveIt.git themes/LoveIt   那么如何更新主题呢？\n1  git submodule update --rebase --remote   把 \\themes\\LoveIt\\exampleSite目录下的config.toml复制下来，替换掉站点根目录下的同名文件。\n然后对这个文件进行一些自定义修改。\n然后进入根目录下的archetypes文件夹中，修改default.md文件为下面的内容（这个文件是模板文件，通过指令创建的文章将以模板为基础内容）\n1 2 3 4 5 6 7 8 9 10 11 12 13  --- title: \u0026#34;{{ replace .Name \u0026#34;-\u0026#34; \u0026#34; \u0026#34; | title }}\u0026#34; date: {{ .Date }} tags: [\u0026#34;\u0026#34;] categories: [\u0026#34;\u0026#34;] toc: enable: true description: draft: true --- \u0026lt;!--more--\u0026gt;   现在开始撰写文章\n1  hugo new posts/first_post.md   注意，后缀为md，建议使用 Typora 进行编辑。\n首先修改 frontmatter，其中title表示文章标题，date为生成文章当时的时间，tags为标签，categories为目录，toc enable为启用文章目录（需要自己在文章中生成），description为文章摘要，draft表示是否为草稿（写完了文章把这里改为 false 即可），\u0026lt;!--more--\u0026gt;为 LoveIt 主题的摘要标识符，该标识符上方的内容为文章摘要，如果上方为空，则采用 frontmatter 中设置的descriptions为文章摘要。\n例如本文的 frontmatter 为\n1 2 3 4 5 6 7 8  title:\u0026#34;Hugo博客系列(一)\u0026#34;date:2022-01-04T18:40:38+08:00tags:[\u0026#34;Hugo\u0026#34;]categories:[\u0026#34;web\u0026#34;]toc:enable:truedescription:本系列教程第一章讲解了几种常见的博客框架选择，最终以 Hugo 框架为基础，教授了如何在 GitHub pages 上部署个人博客，还使用 GitHub actions 以及一个简单的 bat 脚本实现自动化发布。draft:true  写完了文章进行网页的构建\n1  hugo serve -D -e production   -D表示草稿也要渲染，-serve表示启动一个本地服务器，即时渲染，方便修改。\n注意  hugo serve 的默认运行环境是 development, 而 hugo 的默认运行环境是 production。\n由于本地 development 环境的限制, 评论系统**, **CDN 和 fingerprint 不会在 development 环境下启用。\n你可以使用 hugo serve -e production 命令来开启这些特性。\n   值得一提的是不论输入的是server还是serve都是一样的。\n在浏览器中前往它给出的 http://localhost:1313 就能看到你刚生成的博客了。\n技巧  当你运行 hugo serve 时, 当文件内容更改时, 页面会随着更改自动刷新.   现在再输入指令\n1  hugo -D   这会生成一个 public 目录, 其中包含你网站的所有静态内容和资源. 现在可以将其部署在任何 Web 服务器上。\n确认无误后就要把它发到公网上了，这里采用 GitHub pages 进行部署（当然，也有很多种方法也能达成这一目的）\nGitHub pages部署 如果你是第一次使用 GitHub，请自行搜索如何配置，这里不做讲解！\n首先确保你有一个 GitHub 账号，然后新建一个仓库，名为yourname.github.io，注意，你应该保证这里的 your name 为你的 GitHub 账号名称！然后再进行以下步骤：\n1 2 3 4 5 6 7  cd public git init git remote add origin https://github.com/yourname/yourname.github.io.git #此URL可在你的repo中找到 git add . git commit -m \u0026#34;update %date%,%time%\u0026#34; git push origin master   如果一切顺利的话打开你的 GitHub repo，你就能看到相应的文件了，接着在 settings 页面中下滑，找到 GitHub pages，选择分支master，root路径，然后保存即可。如果你有自己的域名，还可以在下方的custom domain中输入你的域名，等待一段时间就可以用这个域名访问了。\n当然，在此之前你还需要再次修改config.toml文件中的baseURL为https://yourname.github.io，否则发布到网上也无法访问！\nGitHub actions实现自动部署(CI/CD) 是否觉得这个发布太过于繁琐了？别担心，这里提供两种解决方案！分别是本地 bat 脚本和GitHub actions。\n首先是本地 bat 脚本，这将免除每次发布都要敲至少 5 行指令的痛苦。只需要每次要发布的时候双击运行一下程序即可。\n1 2 3 4 5 6  hugo -D cd public git add . git commit -m \u0026#34;update %date%,%time%\u0026#34; git push origin master pause   另一种方法是前往 GitHub，新建一个仓库。\n点击Actions选择simple workflow，内容如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  name:CI#自动化的名称on:push:# push的时候触发branches:# 那些分支需要触发- masterjobs:build:runs-on:ubuntu-latest# 镜像市场steps:- name:checkout# 步骤的名称uses:actions/checkout@v2.3.4#软件市场的名称with:# 参数submodules:true- name:Setup Hugouses:peaceiris/actions-hugo@v2.4.13with:hugo-version:0.91.2extended:true- name:Buildrun:hugo -D- name:Deployuses:peaceiris/actions-gh-pages@v3with:deploy_key:${{ secrets.ACTIONS_DEPLOY_KEY }}EXTERNAL_REPOSITORY:14772/14772.github.io# 注意要修改本处地址PUBLISH_BRANCH:masterPUBLISH_DIR:./public  值得注意的是在最后一条Deploy中应使用with而非env，应使用deploy_key而非其他的名字。但目前网上大部分教程都没提及这一点，甚至有的还错误地使用！\n然后在本地输入以下命令在当前目录下生成密钥对\n1 2 3 4  ssh-keygen -t rsa -b 4096 -C \u0026#34;$(git config user.email)\u0026#34; -f gh-pages -N \u0026#34;\u0026#34; # You will get 2 files: # gh-pages.pub (public key) # gh-pages (private key)   -t rsa表示 rsa 加密，-b 4096则表示长度为 4096bit，-C后面的是备注，-f后面的是文件名，-N是新密语\n现在前往yourname.github.io仓库，选择Settings \u0026gt; Deploy keys \u0026gt; Add deploy key，勾选 Allow write access，内容为公钥(有pub字样的文件)\n再前往之前存放了master.yml文件的仓库，选择Settings \u0026gt; Secrets \u0026gt; New secret，名称填ACTIONS_DEPLOY_KEY，内容为私钥\n然后在站点根目录下执行以下命令\n1 2  git remote add origin https://github.com/yourname/yourrepo. #此repo为你放了master.yml文件的仓库   现在再来写一个 bat 脚本\n1 2 3  git add . git commit -m \u0026#34;update %date%,%time%\u0026#34; git push origin master   之后直接双击运行它就行了\n第二种做法总的来说就是两个仓库，一个存源码，一个放网页文件，这样一来你只需要 public 放网页文件的仓库就行，另外一个可以 private，这样一来隐私保护会更好！但是要麻烦一点。\n","permalink":"https://sukun.xyz/hugo-1/","tags":["Hugo"],"title":"Hugo博客系列(一)"},{"categories":["网安"],"contents":"浅析“翻墙” 警告  声明   撰写本文是出于学习计算机网络知识，解析技术以及简单普法的目的。不传播、售卖“翻墙”工具，不教授“翻墙”方法，本文也不出现“翻墙”教程。本人对网民浏览本文后做出的不理智行为概不负责！\n什么是“翻墙”？ 首先，我们要知道翻墙翻的是什么？答案是 GFW(Great Fire Wall)也就是长城防火墙。这里借用维基百科来解释：防火长城（英语：Great Firewall，常用简称：GFW），中文也称中国国家防火墙，俗称墙、网络长城、防火墙等等，中国国家互联网信息办公室称为数据跨境安全网关 ，是中华人民共和国政府监控和过滤互联网国际出口内容的软硬件系统集合。随着使用的拓广，“墙”有时也被用作动词，中国网友所说的“被墙”即指网站内容被防火长城所屏蔽或者指服务器的通讯被封阻，“翻墙”也被引申为突破网络审查浏览中国大陆境外被屏蔽的网站或使用服务的行为。\n为什么要“翻墙” 一方面，普通人翻墙原因如下：\n 使用国外的 app 和服务，例如看 YouTube，使用海外版腾讯视频（海外版往往比国内版体验感好，无广告简洁）。 好奇，想见识一下墙外的世界。（这点原因是主要因素，大多数人都是出于这一点） 满足在国内无法实现的欲望，比如逛 P 站（懂的都懂） 与外国人聊天，增长外语水平 做外贸，面外海外经商却不想支付昂贵的官方信道费用 \u0026hellip;\u0026hellip;  另一方面，作为一名程序员，其翻墙原因如下：\n 使用 GitHub，对于一名程序员来说，GitHub 算得上是必需品，根本离不开 逛 StackOverflow 社区，寻找 bug 解决方案 下载、使用专业工具，因为有些工具是海外的，国内没有替代品 查阅文档、学习技术 阅读科研论文、查询数据、与海外团队交流 \u0026hellip;\u0026hellip;  ”翻墙“犯法吗？ 需要明确的是，在这一问题上，国内暂无一个统一见解。但我个人观点是只要不传播、不扩散、不进行违法违规活动，不发表、不转发、不支持反动言论，只是简单地浏览，同时也没有人举报你翻墙了，那么警察也不会闲得来抓你。\n引用  《计算机信息网络国际互联网安全保护管理办法》（以下简称其为“办法”）第5条规定，任何单位和个人不得利用国际互联网制作、复制、查阅和传播下列信息：\n（一）煽动抗拒、破坏宪法和法律、行政法规实施的；\n（二）煽动颠覆国家政权，推翻社会主义制度的；\n（三）煽动分裂国家、破坏国家统一的；\n（四）煽动民族仇恨、民族歧视，破坏民族团结的；\n（五）捏造或者歪曲事实，散布谣言，扰乱社会秩序的；\n（六）宣扬封建迷信、淫秽、色情、赌博、暴力、凶杀、恐怖、教唆犯罪的；\n（七）公然侮辱他人或者捏造事实诽谤他人的；\n（八）损害国家机关信誉的；\n（九）其他违反宪法和法律、行政法规的。\n   如果按照上述规定，那么在翻墙过程中将难免会遇到不良内容，容易触犯该办法。而这也警示我们：不传播、不扩散、不进行有违法律法规的网络活动！\n另一方面，国内翻墙用户众多，所谓法不责众，如果按照翻墙即违法来处办的话，这对于警力要求过高。按照下图显示的份额来看，谷歌 2020 年在中国就有着 3.49% 的市场份额，而 2020 年中国网民共计 9.40亿，不难得出中国有3200万谷歌用户的数据，如果我们保守估计，以其中有一半的人都有着正规渠道访问谷歌（比如各高校、科研实验室、跨国公司、银行等有资质购买专线的），那么具有翻墙能力的人也有 1600 万之巨，这已经是一个庞大的数字，这也是国内对翻墙不再如从前那么敏感的原因之一。\n同时，近些年来国民的民族自豪感、国家认同感大幅提升，这一现象在年轻人身上表现尤为明显，恰如年轻一辈的口号“请党放心，强国有我”。这使得 GFW 封锁国民访问外网的一大原因——防止国外媒体恶意抹黑中国的言论对国民的思想造成影响——不怎么适用，因为国民不再容易被误导了，”国外的空气也不怎么香甜“。并且有能力进行翻墙的人大多数都是接受了高等教育的人，思想较为深刻，有稳固而正确的三观，放他们出去逛一逛问题也不是很大。\n当然了，如果你不是一个普通的翻墙用户，而是以此牟利，那你肯定触犯了法律，必将接受法律的制裁。一方面，你使得国家将面对更多的不可确定因素，因为受传播者不一定遵纪守法，你需要为此负责！\n引用  除了办法中的条例以外，对提供“翻墙”服务的卖家而言，《互联网信息服务管理办法》 规定的惩罚措施更重。\n第 4 条规定：“国家对经营性互联网信息服务实行许可制度；对非经营性互联网信息服务实行备案制度。未取得许可或者未履行备案手续的，不得从事互联网信息服务。”\n第 19 条规定：“违反本办法的规定，未取得经营许可证，擅自从事经营性互联网信息服务，或者超出许可的项目提供服务的，由省、自治区、直辖市电信管理机构责令限期改正，有违法所得的，没收违法所得，处违法所得 3 倍以上 5 倍以下的罚款；没有违法所得或者违法所得不足 5 万元的，处 10 万元以上 100 万元以下的罚款；情节严重的，责令关闭网站。”\n   总结：作为一名普通翻墙用户，只要老老实实地，不犯法。而如果你进行了违法乱纪的活动，或者是翻墙服务提供商或者教授、传播翻墙方法，那就犯法了！\n“翻墙”原理解析 要知道翻墙的原理，我们就得先知道GFW是如何把这堵墙树立起来，如何阻断不正常通信的。\nGFW的封锁 关键字过滤 由于 Http 协议数据包头部是明文的，所以 GFW 一旦发现连接有敏感词，马上就会伪装成连接两方，向真正的对方发送 RST 数据包（重置连接、复位连接），真正的双方一看，出现异常了，TCP连接就会中断掉。表现为有的页面正在打开，然后过了一会又没了，显示无法连接。\nIP封锁 GFW 可以在出境的网关上加一条伪造的路由规则，这样对于一些被过滤了的 IP 的数据包就无法正确地被送达，所以也就无法访问了。GFW 封路由是直接封独立 IP ，这样可能因为某个敏感站点，导致跟他同一台主机的其他站点也无法访问，理解起来就像旁注（从旁注入）。而且 GFW 封 IP 有的时候是直接封 IP 段的，国外几大 VPS 服务商（比如 Bandwagon 搬瓦工）更是重点监测，有时就因为其中一个 IP 不对，GFW 能给你把这整个机房里的服务器的 IP 全封了，当然这样一来难免会有无辜之人中枪。\nDNS污染、劫持 ​\tDNS 也就是域名解析服务，GFW 会对所有经过骨干出口路由的在 UDP 的 53 端口上的域名查询进行检测，一旦发现有黑名单里的域名，它就会伪装成目标域名的解析服务器给查询者返回虚假结果。由于 UDP 是一种无连接不可靠的协议，查询者只能接受最先返回的结果，故而你将看到明明地址栏中的 URL 是对的，但是浏览器渲染的却是不是目标网页或者干脆访问不了。\n特定端口封锁 对于一些特点的 IP ，GFW 会丢弃特定端口上的数据包，使得某些功能无法使用，比如 443 端口 SSL，22 端口的 SSH。\nGWF 曾经干过一件事，针对 Google 的一些 IP 上的 443 端口，实施间歇性封锁，不明所以的用户就会觉得这是 Google 抽风了，久而久之自然不能忍受 “老是出问题” 的产品。同样的还有 GitHub 的 443 端口、前段时间的 steam 的 443 端口也都被间歇性封锁了。\n值得一提的是这个一般是人为干预的，理由就是常发生在白天。加密连接干扰 加密连接不总是加密的，公钥还是明文的，所以 GFW 就能识别出特定服务的证书。然后在遇到 “黑名单” 加密连接时，它会发送RST数据包，干扰双方正常的 TCP 连接，进而切断加密连接的握手。\n主动嗅探 现在我们假设你能伪装你的流量，当它和其他流量混杂在一起时从外观上看没有什么区别，你以为这就可以高枕无忧了？错！事实上，GFW 是被动监测+主动嗅探来实现封锁的，即使一个流量没有任何翻墙特征，但是这股流量太大了，或者时间太长了，GFW 也将主动地发一个连接请求过去，由于这根本就是个假流量，连接返回的内容也不正常，GFW 一看就知道不对劲了，然后再来个人工检测，你不就暴露了么。另一方面，每逢政治敏感时期（比如每年两会、国庆、建党节）或者每年 6 月的大扫除时期，这个时期人工检测大大增多， GFW 敏感系数提升，更容易发现不正常流量，并且从前稳妥起见，只是怀疑还怕误杀的流量，放在这个时期就大概率给你封了。\n对抗GFW的技术 直接访问IP GFW 不是对域名进行各种干扰吗，现在我直接绕过域名解析，对那些还进入监控名单的 IP 直接访问就能躲开 GFW 的干扰。但是很可惜 GFW 对付这种方法的策略也很简单粗暴但有效，那就是见一个封一个。比如早些年谷歌在国内还能正常访问靠的就是大量的镜像 IP，但随着这些年来 GFW 的不懈努力，谷歌服务的 IP 已经被杀绝了。这种办法的失效也就是个时间问题，因为人家封锁只需要找到 IP 然后加入黑名单就行，而被封锁的一方的要付出的努力就大得多了。\nVPN隧道 首先我们明确，虚拟专用网络（VPN）是一门网络技术，而非一个软件，它为我们提供了一种通过公用网络(如最大的公用因特网)安全地对企业内部专用网络进行远程访问的连接方式。在 VPN 隧道中通信能确保通信通道的专用性，并且传输的数据是经过压缩、加密的，所以VPN通信同样具有专用网络的通信安全性。VPN 原本用意是为了让人不在公司也能访问公司内网，但其优越的安全性也让他也有了对抗 GFW 的功能，这里不展开讲解。但是值得注意的是，那些名叫某某加速器、某某 VPN 的翻墙工具往往都不咋地，而且还有跑路的风险，甚至有的还是“家庭小作坊”，而那些大的服务商提供的虽然稳定速度快，但是又是重点监测，譬如某海外服务商的 VPN 长期坚挺，一直加 IP 来对抗 GFW ，但代价就是价格高昂。就像这张图讲的道理：\n代理服务器 这里故意把 VPN 和代理分开，事实上 VPN 也是代理的一种，但其在网络七层协议中跑在数据链路层/第二层，而socks5、Trojan、v2ray之类的则是在OSI七层模型中的第五层/会话层的，（ HTTP 在第七层/应用层， Ping 指令使用 ICMP 协议，工作于第三层/网络层）。而更低层可以代理更高层，更高层代理不了更底层。表现出来的则是你挂了梯子（非 VPN 类）发现依然没法加速 LOL 等游戏（游戏跑网络层），这也是你再挂了梯子之后依然可以用 Ping 来看主机与服务器直接的延迟的原因。但如果开了 VPN ，那他可以加速游戏，可以代理 ICMP 指令。\n说完了 VPN 与这里说的代理的区别，现在再来说常见的几种“翻墙”代理协议。\n注意  世界上没有永远安全的协议，所谓道高一尺，魔高一丈，这是一场长期的军备竞赛，双方都在不断推陈出新！   Socks5 协议与 HTTP 协议 Socks5 把你的网络数据由代理服务器转发到目的地，这个过程中你是没有一条专用通道的，只是数据包的发出，然后被代理服务器收到，然后代理服务器再进行转发，整个过程并没有额外的处理。\n但是在连接建立时、传输流量过程中有着极为明显的流量特征。因此网上也不乏唱衰 Socks5 协议的声音，甚至有流言称 Socks5 协议已被 GFW 攻破，能被其拿捏，但目前暂无明确证据，同时 Socks5协议依然是用的最多的代理协议，因此我对这种观点持保留观点。\n对抗措施：流量加密、反检测、免杀\n Socks5 + HTTP 代理并不会让本来明文传输的浏览加密，但是可以改变请求的 IP，服务器看到访问者的 IP 就是你的代理代理服务器的IP。 如果流量本身没有加密，实战中流控设备很容易识别到客户端连接成功的流量规则。 如果想要加密 Socks5 的流量，则需要安装魔改版 Socks 服务端和客户端，比如著名的 SS/SSR 就是用 Socks5 来实现的，Cobalt Strike 也有相关插件对流量进行加密。  v2ray协议 VMess协议 VMess 协议是由 V2Ray 原创并使用于 V2Ray 的加密传输协议，如同 Shadow socks 一样为了对抗墙的深度包检测而研发的。在 V2Ray 上客户端与服务器的通信主要是通过 VMess 协议通信。\nVLESS协议 VLESS 是一种无状态的轻量级数据传输协议，被定义为下一代 V2ray 数据传输协议。作者对该协议的愿景是“可扩展性空前，适合随意组合、全场景广泛使用，符合很多人的设想、几乎所有人的需求，足以成为 v2ray 的下一代主要协议，乃至整个 XX 界的终极协议。”，由此可见 VLESS 协议的强大。\n注意  VLESS 命名源自“less is more”，写法与 VMess 近似   VLESS和VMESS区别如下：\n VLESS协议不依赖于系统时间，不使用 alterId 。一些人的 V2ray 用不了，最后找出原因是电脑时间和服务器只相差两分钟，简直要让人抓狂；VLESS 协议去掉了时间要求，双手举赞； VLESS 协议不带加密，用于科学上网时要配合TLS等加密手段； VLESS 协议支持分流和回落，比 Nginx 分流转发更简洁、高效和安全； 使用TLS的情况下，VLESS 协议比 VMESS 速度更快，性能更好，因为 VLESS 不会对数据进行加解密； V2ray 官方对 VLESS 的期望更高，约束也更严格。例如要求客户端统一使用 VLESS 标识，而不是 Vless 、vless 等名称；VLESS 分享链接标准将由官方统一制定（尚未出炉）； VLESS 协议的加密更灵活，不像 VMESS 一样高度耦合（仅对开发者有用）  对于普通用户来说，VLESS 协议的主要优势是：1. 不需要客户端和服务器时间一致； 2. VLESS 协议不自带加密，使用 TLS 的情况下性能比 VMESS 更好。\nXTLS协议 XTLS官方库 的介绍仅有一句话：THE FUTURE。V2fly 官网（V2fly 社区是 V2ray 技术的主要推动力量） 称 XTLS为黑科技，VLESS协议作者的形容是：划时代的革命性概念和技术。\nXTLS 的原理是：使用 TLS 代理时，https 数据其实经过了两层 TLS：外层是代理的 TLS，内层是 https 的 TLS。XTLS 无缝拼接了内外两条货真价实的 TLS，使得代理几乎无需再对 https 流量进行数据加解密，只起到流量中转的作用，极大的提高了性能。\nVLESS + XTLS 的组合可以理解为是增强版 ECH，即多支持身份认证、代理转发、明文加密、UDP over TCP 等。但从其原理可知，VLESS + XTLS对http流量是没有多大优势的。好消息是，目前超过 90% 的流量都是 https 的，因此 VLESS + XTLS 能极大的提升性能，无愧于上面的评价。\n注意  需要说明的是，XTLS 是科学上网的 future ，不是 TLS 发展的 future。   Trojan协议 Trojan 协议简单来说是通过 TLS 协议（安全传输层协议）伪装成访问 HTTPS（超文本传输协议）的正常流量。由于 TLS 是一个完整的加密协议通过目前的任何技术手段都无法得到其加密内容，所以 Trojan 的安全性可见一斑。但目前 Trojan 还属于是一个新兴的技术，在各方面都存在问题，但其有着最值得期待的未来，我们需要做的是给予其时间，让其成长。\n在安全性方面，GFW 的主动嗅探主要是其接入目标服务器进行数据检测，而 Trojan 和其他协议不同，当 GFW 接入时不会主动断开介入服务，而是会将接入点连接到一个常规的 web 服务器。这个时候 GWF 就会以为这个服务器是一个常规服务器，从而做出错误的判断。当然，如果是人工来检测，进行了精密的流量分析的话 Trojan 也无能为力。\n找 GFW 的 BUG 这个比较少，就是寻找 GFW 的漏洞，然后依次为突破点来翻墙，这里我也没怎么了解，不做展开。\n注意  最后，如果你有任何想法，欢迎来评论区告诉我！  ","permalink":"https://sukun.xyz/%E6%B5%85%E6%9E%90%E7%BF%BB%E5%A2%99/","tags":["翻墙"],"title":"浅析翻墙"},{"categories":["dev"],"contents":"先起个名，寒假有空了再来写","permalink":"https://sukun.xyz/tcp%E9%80%9A%E4%BF%A1python%E5%AE%9E%E7%8E%B0/","tags":["python","TCP"],"title":"TCP通信Python实现"},{"categories":null,"contents":"博主相关情况 电科在读学子，软工专业\n兴趣爱好：\n 游戏（PC、手游） 热爱技术 看剧（不多）  主要研究方向：运维\n联系方式：\n email :1477264431@qq.com csdn :https://blog.csdn.net/sk14772 GitHub :https://github.io/14772  创建博客目的 创建本博客主要用于记录学习过程，并防止后面学着学着忘了以前学的内容\n本站相关情况 hugo v0.91.2-1798BD3F+extended windows/amd64 BuildDate=2021-12-23T15:33:34Z VendorInfo=gohugoio\nLoveIt: v0.2.10\n","permalink":"https://sukun.xyz/about/","tags":null,"title":"About"},{"categories":["web"],"contents":"快速建站  公网访问 docker部署 SSL证书部署 负载均衡  买好一个 VPS ，拿到 ip 地址和管理员密码，ssh 登录上去\n这里采用 docker 部署，首先利用官方脚本安装 docker 并设置开机自启动\n1 2 3  curl -fsSL https://get.docker.com -o get-docker.sh sudo sh get-docker.sh sudo systemctl enable docker   然后启动 Nginx 镜像的容器，把宿主机8080，8443端口转发到容器的80，443端口\n1  docker run -dit --name web -p 8080:80 -p 8443:443 nginx   然后访问一下ip:8080能看到Nginx欢迎界面\n现在进入容器进行配置，首先是安装 vim ，然后写一个简单的网页文件\n1 2 3 4 5  docker exec -it web bash apt update apt install vim cd /etc/nginx/conf.d vim default.conf   然后修改Nginx配置文件中的 root 位置，修改 server_name 为你要绑定的域名，再重启 Nginx 服务（nginx 配置文件详解见文末）\n1  nginx -s reload   这一步完成后就可以看见你写的网页了\n这里考虑到只有一台服务器，因此我的负载均衡思路是搭建Nginx集群，把刚刚写的配置文件和网页文件拷贝到每一个容器中，配置负载均衡，让其中一个容器成为主服务器\n现在要做的就是把配置文件和网页文件拷贝到宿主机中。(这里我登录的 root 用户，所以拷贝到了 root 目录下)然后再映射这两个文件夹到新创建的Nginx集群的每个容器中去。\n1 2 3 4 5 6  docker cp web:/etc/nginx ~/conf docker cp web:/var/www/html ~/html docker run -d -it -p 8081:80 -p 8444:443 --name web1 -v ~/conf:/etc/nginx -v ~/html:/var/www/html nginx docker run -d -it -p 8082:80 -p 8445:443 --name web2 -v ~/conf:/etc/nginx -v ~/html:/var/www/html nginx   这里以web容器为主服务器，首先查看他们的ip地址，然后编辑web的Nginx配置文件（这里顺手把原来的web容器删除，以映射的方式重建了一下，这样就能直接编辑宿主机中的文件就能编辑到映射到容器中的文件）\n1 2  docker network ls docker network inspect f1c912c35ca8   现在就能根据得到的ip地址编辑web容器的default.conf文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  upstream 172.17.0.2 { server 172.17.0.3 weight=1; server 172.17.0.4 weight=2; } server { listen 80; listen 443 ssl; server_name sukunblog.cn sukunblog.cn 172.17.0.2; ssl_certificate /etc/nginx/sukunblog.cn.pem; ssl_certificate_key /etc/nginx/sukunblog.cn.key; ssl_session_timeout 10m; ssl_protocols TLSv1.1 TLSv1.2 TLSv1.3; ssl_ciphers ECDHE-RSA-AES128-GCMSHA256: ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_prefer_server_ciphers on; client_max_body_size 1024m; location / { root /var/www/html; index Hello.html; proxy_set_header HOST $host; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://172.17.0.2; } }   Nginx 配置文件详解 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333  ######Nginx配置文件nginx.conf中文详解#####  #定义Nginx运行的用户和用户组 user www www; #nginx进程数，建议设置为等于CPU总核心数。 worker_processes 8; #全局错误日志定义类型，[ debug | info | notice | warn | error | crit ] error_log /usr/local/nginx/logs/error.log info; #进程pid文件 pid /usr/local/nginx/logs/nginx.pid; #指定进程可以打开的最大描述符：数目 #工作模式与连接数上限 #这个指令是指当一个nginx进程打开的最多文件描述符数目，理论值应该是最多打开文件数（ulimit -n）与nginx进程数相除，但是nginx分配请求并不是那么均匀，所以最好与ulimit -n 的值保持一致。 #现在在linux 2.6内核下开启文件打开数为65535，worker_rlimit_nofile就相应应该填写65535。 #这是因为nginx调度时分配请求到进程并不是那么的均衡，所以假如填写10240，总并发量达到3-4万时就有进程可能超过10240了，这时会返回502错误。 worker_rlimit_nofile 65535; events { #参考事件模型，use [ kqueue | rtsig | epoll | /dev/poll | select | poll ]; epoll模型  #是Linux 2.6以上版本内核中的高性能网络I/O模型，linux建议epoll，如果跑在FreeBSD上面，就用kqueue模型。  #补充说明：  #与apache相类，nginx针对不同的操作系统，有不同的事件模型  #A）标准事件模型  #Select、poll属于标准事件模型，如果当前系统不存在更有效的方法，nginx会选择select或poll  #B）高效事件模型  #Kqueue：使用于FreeBSD 4.1+, OpenBSD 2.9+, NetBSD 2.0 和 MacOS X.使用双处理器的MacOS X系统使用kqueue可能会造成内核崩溃。  #Epoll：使用于Linux内核2.6版本及以后的系统。  #/dev/poll：使用于Solaris 7 11/99+，HP/UX 11.22+ (eventport)，IRIX 6.5.15+ 和 Tru64 UNIX 5.1A+。  #Eventport：使用于Solaris 10。 为了防止出现内核崩溃的问题， 有必要安装安全补丁。  use epoll; #单个进程最大连接数（最大连接数=连接数*进程数）  #根据硬件调整，和前面工作进程配合起来用，尽量大，但是别把cpu跑到100%就行。每个进程允许的最多连接数，理论上每台nginx服务器的最大连接数为。  worker_connections 65535; #keepalive超时时间。  keepalive_timeout 60; #客户端请求头部的缓冲区大小。这个可以根据你的系统分页大小来设置，一般一个请求头的大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。  #分页大小可以用命令getconf PAGESIZE 取得。  #[root@web001 ~]# getconf PAGESIZE  #4096  #但也有client_header_buffer_size超过4k的情况，但是client_header_buffer_size该值必须设置为“系统分页大小”的整倍数。  client_header_buffer_size 4k; #这个将为打开文件指定缓存，默认是没有启用的，max指定缓存数量，建议和打开文件数一致，inactive是指经过多长时间文件没被请求后删除缓存。  open_file_cache max=65535 inactive=60s; #这个是指多长时间检查一次缓存的有效信息。  #语法:open_file_cache_valid time 默认值:open_file_cache_valid 60 使用字段:http, server, location 这个指令指定了何时需要检查open_file_cache中缓存项目的有效信息.  open_file_cache_valid 80s; #open_file_cache指令中的inactive参数时间内文件的最少使用次数，如果超过这个数字，文件描述符一直是在缓存中打开的，如上例，如果有一个文件在inactive时间内一次没被使用，它将被移除。  #语法:open_file_cache_min_uses number 默认值:open_file_cache_min_uses 1 使用字段:http, server, location 这个指令指定了在open_file_cache指令无效的参数中一定的时间范围内可以使用的最小文件数,如果使用更大的值,文件描述符在cache中总是打开状态.  open_file_cache_min_uses 1; #语法:open_file_cache_errors on | off 默认值:open_file_cache_errors off 使用字段:http, server, location 这个指令指定是否在搜索一个文件是记录cache错误.  open_file_cache_errors on; } #设定http服务器，利用它的反向代理功能提供负载均衡支持 http { #文件扩展名与文件类型映射表  include mime.types; #默认文件类型  default_type application/octet-stream; #默认编码  #charset utf-8;  #服务器名字的hash表大小  #保存服务器名字的hash表是由指令server_names_hash_max_size 和server_names_hash_bucket_size所控制的。参数hash bucket size总是等于hash表的大小，并且是一路处理器缓存大小的倍数。在减少了在内存中的存取次数后，使在处理器中加速查找hash表键值成为可能。如果hash bucket size等于一路处理器缓存的大小，那么在查找键的时候，最坏的情况下在内存中查找的次数为2。第一次是确定存储单元的地址，第二次是在存储单元中查找键 值。因此，如果Nginx给出需要增大hash max size 或 hash bucket size的提示，那么首要的是增大前一个参数的大小.  server_names_hash_bucket_size 128; #客户端请求头部的缓冲区大小。这个可以根据你的系统分页大小来设置，一般一个请求的头部大小不会超过1k，不过由于一般系统分页都要大于1k，所以这里设置为分页大小。分页大小可以用命令getconf PAGESIZE取得。  client_header_buffer_size 32k; #客户请求头缓冲大小。nginx默认会用client_header_buffer_size这个buffer来读取header值，如果header过大，它会使用large_client_header_buffers来读取。  large_client_header_buffers 4 64k; #设定通过nginx上传文件的大小  client_max_body_size 8m; #开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，对于普通应用设为 on，如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。注意：如果图片显示不正常把这个改成off。  #sendfile指令指定 nginx 是否调用sendfile 函数（zero copy 方式）来输出文件，对于普通应用，必须设为on。如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络IO处理速度，降低系统uptime。  sendfile on; #开启目录列表访问，合适下载服务器，默认关闭。  autoindex on; #此选项允许或禁止使用socke的TCP_CORK的选项，此选项仅在使用sendfile的时候使用  tcp_nopush on; tcp_nodelay on; #长连接超时时间，单位是秒  keepalive_timeout 120; #FastCGI相关参数是为了改善网站的性能：减少资源占用，提高访问速度。下面参数看字面意思都能理解。  fastcgi_connect_timeout 300; fastcgi_send_timeout 300; fastcgi_read_timeout 300; fastcgi_buffer_size 64k; fastcgi_buffers 4 64k; fastcgi_busy_buffers_size 128k; fastcgi_temp_file_write_size 128k; #gzip模块设置  gzip on; #开启gzip压缩输出  gzip_min_length 1k; #最小压缩文件大小  gzip_buffers 4 16k; #压缩缓冲区  gzip_http_version 1.0; #压缩版本（默认1.1，前端如果是squid2.5请使用1.0）  gzip_comp_level 2; #压缩等级  gzip_types text/plain application/x-javascript text/css application/xml; #压缩类型，默认就已经包含textml，所以下面就不用再写了，写上去也不会有问题，但是会有一个warn。  gzip_vary on; #开启限制IP连接数的时候需要使用  #limit_zone crawler $binary_remote_addr 10m;  #负载均衡配置  upstream piao.jd.com { #upstream的负载均衡，weight是权重，可以根据机器配置定义权重。weigth参数表示权值，权值越高被分配到的几率越大。  server 192.168.80.121:80 weight=3; server 192.168.80.122:80 weight=2; server 192.168.80.123:80 weight=3; #nginx的upstream目前支持4种方式的分配  #1、轮询（默认）  #每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。  #2、weight  #指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。  #例如：  #upstream bakend {  # server 192.168.0.14 weight=10;  # server 192.168.0.15 weight=10;  #}  #2、ip_hash  #每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。  #例如：  #upstream bakend {  # ip_hash;  # server 192.168.0.14:88;  # server 192.168.0.15:80;  #}  #3、fair（第三方）  #按后端服务器的响应时间来分配请求，响应时间短的优先分配。  #upstream backend {  # server server1;  # server server2;  # fair;  #}  #4、url_hash（第三方）  #按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。  #例：在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法  #upstream backend {  # server squid1:3128;  # server squid2:3128;  # hash $request_uri;  # hash_method crc32;  #}  #tips:  #upstream bakend{#定义负载均衡设备的Ip及设备状态}{  # ip_hash;  # server 127.0.0.1:9090 down;  # server 127.0.0.1:8080 weight=2;  # server 127.0.0.1:6060;  # server 127.0.0.1:7070 backup;  #}  #在需要使用负载均衡的server中增加 proxy_pass http://bakend/;  #每个设备的状态设置为:  #1.down表示单前的server暂时不参与负载  #2.weight为weight越大，负载的权重就越大。  #3.max_fails：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream模块定义的错误  #4.fail_timeout:max_fails次失败后，暂停的时间。  #5.backup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。  #nginx支持同时设置多组的负载均衡，用来给不用的server来使用。  #client_body_in_file_only设置为On 可以讲client post过来的数据记录到文件中用来做debug  #client_body_temp_path设置记录文件的目录 可以设置最多3层目录  #location对URL进行匹配.可以进行重定向或者进行新的代理 负载均衡  } #虚拟主机的配置  server { #监听端口  listen 80; #域名可以有多个，用空格隔开  server_name www.jd.com jd.com; index index.html index.htm index.php; root /data/www/jd; #fastcgi解析php  location ~ .*.(php|php5)?$ { #此处有两种方式去和php-fpm交互,一种是9000端口,另一种是使用socket连接  fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include fastcgi.conf; } #图片缓存时间设置  location ~ .*.(gif|jpg|jpeg|png|bmp|swf)$ { expires 10d; } #JS和CSS缓存时间设置  location ~ .*.(js|css)?$ { expires 1h; } #日志格式设定  #$remote_addr与$http_x_forwarded_for用以记录客户端的ip地址；  #$remote_user：用来记录客户端用户名称；  #$time_local： 用来记录访问时间与时区；  #$request： 用来记录请求的url与http协议；  #$status： 用来记录请求状态；成功是200，  #$body_bytes_sent ：记录发送给客户端文件主体内容大小；  #$http_referer：用来记录从那个页面链接访问过来的；  #$http_user_agent：记录客户浏览器的相关信息；  #通常web服务器放在反向代理的后面，这样就不能获取到客户的IP地址了，通过$remote_add拿到的IP地址是反向代理服务器的iP地址。反向代理服务器在转发请求的http头信息中，可以增加x_forwarded_for信息，用以记录原有客户端的IP地址和原来客户端的请求的服务器地址。  log_format access \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; $http_x_forwarded_for\u0026#39;; #定义本虚拟主机的访问日志  access_log /usr/local/nginx/logs/host.access.log main; access_log /usr/local/nginx/logs/host.access.404.log log404; #对 \u0026#34;/\u0026#34; 启用反向代理  location / { proxy_pass http://127.0.0.1:88; proxy_redirect off; proxy_set_header X-Real-IP $remote_addr; #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP  proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; #以下是一些反向代理的配置，可选。  proxy_set_header Host $host; #允许客户端请求的最大单文件字节数  client_max_body_size 10m; #缓冲区代理缓冲用户端请求的最大字节数，  #如果把它设置为比较大的数值，例如256k，那么，无论使用firefox还是IE浏览器，来提交任意小于256k的图片，都很正常。如果注释该指令，使用默认的client_body_buffer_size设置，也就是操作系统页面大小的两倍，8k或者16k，问题就出现了。  #无论使用firefox4.0还是IE8.0，提交一个比较大，200k左右的图片，都返回500 Internal Server Error错误  client_body_buffer_size 128k; #表示使nginx阻止HTTP应答代码为400或者更高的应答。  proxy_intercept_errors on; #后端服务器连接的超时时间_发起握手等候响应超时时间  #nginx跟后端服务器连接超时时间(代理连接超时)  proxy_connect_timeout 90; #后端服务器数据回传时间(代理发送超时)  #后端服务器数据回传时间_就是在规定时间之内后端服务器必须传完所有的数据  proxy_send_timeout 90; #连接成功后，后端服务器响应时间(代理接收超时)  #连接成功后_等候后端服务器响应时间_其实已经进入后端的排队之中等候处理（也可以说是后端服务器处理请求的时间）  proxy_read_timeout 90; #设置代理服务器（nginx）保存用户头信息的缓冲区大小  #设置从被代理服务器读取的第一部分应答的缓冲区大小，通常情况下这部分应答中包含一个小的应答头，默认情况下这个值的大小为指令proxy_buffers中指定的一个缓冲区的大小，不过可以将其设置为更小  proxy_buffer_size 4k; #proxy_buffers缓冲区，网页平均在32k以下的设置  #设置用于读取应答（来自被代理服务器）的缓冲区数目和大小，默认情况也为分页大小，根据操作系统的不同可能是4k或者8k  proxy_buffers 4 32k; #高负荷下缓冲大小（proxy_buffers*2）  proxy_busy_buffers_size 64k; #设置在写入proxy_temp_path时数据的大小，预防一个工作进程在传递文件时阻塞太长  #设定缓存文件夹大小，大于这个值，将从upstream服务器传  proxy_temp_file_write_size 64k; } #设定查看Nginx状态的地址  location /NginxStatus { stub_status on; access_log on; auth_basic \u0026#34;NginxStatus\u0026#34;; auth_basic_user_file confpasswd; #htpasswd文件的内容可以用apache提供的htpasswd工具来产生。  } #本地动静分离反向代理配置  #所有jsp的页面均交由tomcat或resin处理  location ~ .(jsp|jspx|do)?$ { proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://127.0.0.1:8080; } #所有静态文件由nginx直接读取不经过tomcat或resin  location ~ .*.(htm|html|gif|jpg|jpeg|png|bmp|swf|ioc|rar|zip|txt|flv|mid|doc|ppt| pdf|xls|mp3|wma)$ { expires 15d; } location ~ .*.(js|css)?$ { expires 1h; } } } ######Nginx配置文件nginx.conf中文详解#####   ","permalink":"https://sukun.xyz/%E7%AE%80%E6%98%93%E5%BB%BA%E7%AB%99/","tags":["Nginx"],"title":"简易建站"},{"categories":null,"contents":"","permalink":"https://sukun.xyz/search/","tags":null,"title":"Search"}]